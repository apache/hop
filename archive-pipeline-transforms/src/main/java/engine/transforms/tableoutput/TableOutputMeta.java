/*! ******************************************************************************
 *
 * Hop : The Hop Orchestration Platform
 *
 * http://www.project-hop.org
 *
 *******************************************************************************
 *
 * Licensed under the Apache License, Version 2.0 (the "License");
 * you may not use this file except in compliance with
 * the License. You may obtain a copy of the License at
 *
 *    http://www.apache.org/licenses/LICENSE-2.0
 *
 * Unless required by applicable law or agreed to in writing, software
 * distributed under the License is distributed on an "AS IS" BASIS,
 * WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 * See the License for the specific language governing permissions and
 * limitations under the License.
 *
 ******************************************************************************/

package org.apache.hop.pipeline.transforms.tableoutput;

import com.google.common.base.Preconditions;
import org.apache.hop.core.CheckResult;
import org.apache.hop.core.CheckResultInterface;
import org.apache.hop.core.Const;
import org.apache.hop.core.ProvidesModelerMeta;
import org.apache.hop.core.SQLStatement;
import org.apache.hop.core.database.Database;
import org.apache.hop.core.database.DatabaseMeta;
import org.apache.hop.core.exception.HopDatabaseException;
import org.apache.hop.core.exception.HopException;
import org.apache.hop.core.exception.HopTransformException;
import org.apache.hop.core.exception.HopXMLException;
import org.apache.hop.core.row.RowMeta;
import org.apache.hop.core.row.IRowMeta;
import org.apache.hop.core.row.IValueMeta;
import org.apache.hop.core.row.value.ValueMetaInteger;
import org.apache.hop.core.util.Utils;
import org.apache.hop.core.variables.iVariables;
import org.apache.hop.core.xml.XMLHandler;
import org.apache.hop.i18n.BaseMessages;
import org.apache.hop.metastore.api.IMetaStore;
import org.apache.hop.pipeline.DatabaseImpact;
import org.apache.hop.pipeline.Pipeline;
import org.apache.hop.pipeline.PipelineMeta;
import org.apache.hop.pipeline.transform.BaseTransformMeta;
import org.apache.hop.pipeline.transform.ITransformData;
import org.apache.hop.pipeline.transform.TransformInjectionMetaEntry;
import org.apache.hop.pipeline.transform.ITransform;
import org.apache.hop.pipeline.transform.TransformMeta;
import org.apache.hop.pipeline.transform.ITransform;
import org.w3c.dom.Node;

import java.util.Arrays;
import java.util.Collections;
import java.util.List;

/**
 * Table Output meta data.
 *
 * @author Matt Casters
 * @since 2-jun-2003
 */
public class TableOutputMeta extends BaseTransformMeta implements ITransform, ProvidesModelerMeta {
  private static Class<?> PKG = TableOutputMeta.class; // for i18n purposes, needed by Translator!!

  private DatabaseMeta databaseMeta;
  private String schemaName;
  private String tableName;
  private String commitSize;
  private boolean truncateTable;
  private boolean ignoreErrors;
  private boolean useBatchUpdate;

  private boolean partitioningEnabled;
  private String partitioningField;
  private boolean partitioningDaily;
  private boolean partitioningMonthly;

  private boolean tableNameInField;
  private String tableNameField;
  private boolean tableNameInTable;

  private boolean returningGeneratedKeys;
  private String generatedKeyField;

  /**
   * Do we explicitly select the fields to update in the database
   */
  private boolean specifyFields;

  /**
   * Fields containing the values in the input stream to insert
   */
  private String[] fieldStream;

  /**
   * Fields in the table to insert
   */
  private String[] fieldDatabase;

  /**
   * @return Returns the generatedKeyField.
   */
  public String getGeneratedKeyField() {
    return generatedKeyField;
  }

  /**
   * @param generatedKeyField The generatedKeyField to set.
   */
  public void setGeneratedKeyField( String generatedKeyField ) {
    this.generatedKeyField = generatedKeyField;
  }

  /**
   * @return Returns the returningGeneratedKeys.
   */
  public boolean isReturningGeneratedKeys() {
    if ( getDatabaseMeta() != null ) {
      return getDatabaseMeta().supportsAutoGeneratedKeys() && returningGeneratedKeys;
    }
    return false;
  }

  /**
   * @param returningGeneratedKeys The returningGeneratedKeys to set.
   */
  public void setReturningGeneratedKeys( boolean returningGeneratedKeys ) {
    this.returningGeneratedKeys = returningGeneratedKeys;
  }

  /**
   * @return Returns the tableNameInTable.
   */
  public boolean isTableNameInTable() {
    return tableNameInTable;
  }

  /**
   * @param tableNameInTable The tableNameInTable to set.
   */
  public void setTableNameInTable( boolean tableNameInTable ) {
    this.tableNameInTable = tableNameInTable;
  }

  /**
   * @return Returns the tableNameField.
   */
  public String getTableNameField() {
    return tableNameField;
  }

  /**
   * @param tableNameField The tableNameField to set.
   */
  public void setTableNameField( String tableNameField ) {
    this.tableNameField = tableNameField;
  }

  /**
   * @return Returns the tableNameInField.
   */
  public boolean isTableNameInField() {
    return tableNameInField;
  }

  /**
   * @param tableNameInField The tableNameInField to set.
   */
  public void setTableNameInField( boolean tableNameInField ) {
    this.tableNameInField = tableNameInField;
  }

  /**
   * @return Returns the partitioningDaily.
   */
  public boolean isPartitioningDaily() {
    return partitioningDaily;
  }

  /**
   * @param partitioningDaily The partitioningDaily to set.
   */
  public void setPartitioningDaily( boolean partitioningDaily ) {
    this.partitioningDaily = partitioningDaily;
  }

  /**
   * @return Returns the partitioningMontly.
   */
  public boolean isPartitioningMonthly() {
    return partitioningMonthly;
  }

  /**
   * @param partitioningMontly The partitioningMontly to set.
   */
  public void setPartitioningMonthly( boolean partitioningMontly ) {
    this.partitioningMonthly = partitioningMontly;
  }

  /**
   * @return Returns the partitioningEnabled.
   */
  public boolean isPartitioningEnabled() {
    return partitioningEnabled;
  }

  /**
   * @param partitioningEnabled The partitioningEnabled to set.
   */
  public void setPartitioningEnabled( boolean partitioningEnabled ) {
    this.partitioningEnabled = partitioningEnabled;
  }

  /**
   * @return Returns the partitioningField.
   */
  public String getPartitioningField() {
    return partitioningField;
  }

  /**
   * @param partitioningField The partitioningField to set.
   */
  public void setPartitioningField( String partitioningField ) {
    this.partitioningField = partitioningField;
  }

  public TableOutputMeta() {
    super(); // allocate BaseTransformMeta
    useBatchUpdate = true;
    commitSize = "1000";

    fieldStream = new String[ 0 ];
    fieldDatabase = new String[ 0 ];
  }

  public void allocate( int nrRows ) {
    fieldStream = new String[ nrRows ];
    fieldDatabase = new String[ nrRows ];
  }

  public void loadXML( Node transformNode, IMetaStore metaStore ) throws HopXMLException {
    readData( transformNode, metaStore );
  }

  public Object clone() {
    Preconditions.checkState( fieldStream.length == fieldDatabase.length,
      "Table fields and stream fields are not of equal length." );
    TableOutputMeta retval = (TableOutputMeta) super.clone();
    int nrRows = fieldStream.length;
    retval.allocate( nrRows );
    System.arraycopy( fieldStream, 0, retval.fieldStream, 0, nrRows );
    System.arraycopy( fieldDatabase, 0, retval.fieldDatabase, 0, nrRows );

    return retval;
  }

  /**
   * @return Returns the database.
   */
  public DatabaseMeta getDatabaseMeta() {
    return databaseMeta;
  }

  /**
   * @param database The database to set.
   */
  public void setDatabaseMeta( DatabaseMeta database ) {
    this.databaseMeta = database;
  }

  /**
   * @return Returns the commitSize.
   */
  public String getCommitSize() {
    return commitSize;
  }

  /**
   * @param commitSizeInt The commitSize to set.
   */
  public void setCommitSize( int commitSizeInt ) {
    this.commitSize = Integer.toString( commitSizeInt );
  }

  /**
   * @param commitSize The commitSize to set.
   */
  public void setCommitSize( String commitSize ) {
    this.commitSize = commitSize;
  }

  /**
   * @return the table name
   */
  public String getTableName() {
    return tableName;
  }

  /**
   * Assign the table name to write to.
   *
   * @param tableName The table name to set
   */
  public void setTableName( String tableName ) {
    this.tableName = tableName;
  }

  /**
   * @return Returns the tablename.
   * @deprecated Use {@link #getTableName()}
   */
  @Deprecated
  public String getTablename() {
    return getTableName();
  }

  /**
   * @param tablename The tablename to set.
   * @deprecated Use {@link #setTableName(String)}
   */
  @Deprecated
  public void setTablename( String tablename ) {
    setTableName( tablename );
  }

  /**
   * @return Returns the truncate table flag.
   */
  public boolean truncateTable() {
    return truncateTable;
  }

  /**
   * @param truncateTable The truncate table flag to set.
   */
  public void setTruncateTable( boolean truncateTable ) {
    this.truncateTable = truncateTable;
  }

  /**
   * @param ignoreErrors The ignore errors flag to set.
   */
  public void setIgnoreErrors( boolean ignoreErrors ) {
    this.ignoreErrors = ignoreErrors;
  }

  /**
   * @return Returns the ignore errors flag.
   */
  public boolean ignoreErrors() {
    return ignoreErrors;
  }

  /**
   * @param specifyFields The specify fields flag to set.
   */
  public void setSpecifyFields( boolean specifyFields ) {
    this.specifyFields = specifyFields;
  }

  /**
   * @return Returns the specify fields flag.
   */
  public boolean specifyFields() {
    return specifyFields;
  }

  /**
   * @param useBatchUpdate The useBatchUpdate flag to set.
   */
  public void setUseBatchUpdate( boolean useBatchUpdate ) {
    this.useBatchUpdate = useBatchUpdate;
  }

  /**
   * @return Returns the useBatchUpdate flag.
   */
  public boolean useBatchUpdate() {
    return useBatchUpdate;
  }

  private void readData( Node transformNode, IMetaStore metaStore ) throws HopXMLException {
    try {
      String con = XMLHandler.getTagValue( transformNode, "connection" );
      databaseMeta = DatabaseMeta.loadDatabase( metaStore, con );
      schemaName = XMLHandler.getTagValue( transformNode, "schema" );
      tableName = XMLHandler.getTagValue( transformNode, "table" );
      commitSize = XMLHandler.getTagValue( transformNode, "commit" );
      truncateTable = "Y".equalsIgnoreCase( XMLHandler.getTagValue( transformNode, "truncate" ) );
      ignoreErrors = "Y".equalsIgnoreCase( XMLHandler.getTagValue( transformNode, "ignore_errors" ) );
      useBatchUpdate = "Y".equalsIgnoreCase( XMLHandler.getTagValue( transformNode, "use_batch" ) );

      // If not present it will be false to be compatible with pre-v3.2
      specifyFields = "Y".equalsIgnoreCase( XMLHandler.getTagValue( transformNode, "specify_fields" ) );

      partitioningEnabled = "Y".equalsIgnoreCase( XMLHandler.getTagValue( transformNode, "partitioning_enabled" ) );
      partitioningField = XMLHandler.getTagValue( transformNode, "partitioning_field" );
      partitioningDaily = "Y".equalsIgnoreCase( XMLHandler.getTagValue( transformNode, "partitioning_daily" ) );
      partitioningMonthly = "Y".equalsIgnoreCase( XMLHandler.getTagValue( transformNode, "partitioning_monthly" ) );

      tableNameInField = "Y".equalsIgnoreCase( XMLHandler.getTagValue( transformNode, "tablename_in_field" ) );
      tableNameField = XMLHandler.getTagValue( transformNode, "tablename_field" );
      tableNameInTable = "Y".equalsIgnoreCase( XMLHandler.getTagValue( transformNode, "tablename_in_table" ) );

      returningGeneratedKeys = "Y".equalsIgnoreCase( XMLHandler.getTagValue( transformNode, "return_keys" ) );
      generatedKeyField = XMLHandler.getTagValue( transformNode, "return_field" );

      Node fields = XMLHandler.getSubNode( transformNode, "fields" );
      int nrRows = XMLHandler.countNodes( fields, "field" );

      allocate( nrRows );

      for ( int i = 0; i < nrRows; i++ ) {
        Node knode = XMLHandler.getSubNodeByNr( fields, "field", i );

        fieldDatabase[ i ] = XMLHandler.getTagValue( knode, "column_name" );
        fieldStream[ i ] = XMLHandler.getTagValue( knode, "stream_name" );
      }
    } catch ( Exception e ) {
      throw new HopXMLException( "Unable to load transform info from XML", e );
    }
  }

  public void setDefault() {
    databaseMeta = null;
    tableName = "";
    commitSize = "1000";

    partitioningEnabled = false;
    partitioningMonthly = true;
    partitioningField = "";
    tableNameInTable = true;
    tableNameField = "";

    // To be compatible with pre-v3.2 (SB)
    specifyFields = false;
  }

  public String getXML() {
    StringBuilder retval = new StringBuilder();

    retval.append( "    "
      + XMLHandler.addTagValue( "connection", databaseMeta == null ? "" : databaseMeta.getName() ) );
    retval.append( "    " + XMLHandler.addTagValue( "schema", schemaName ) );
    retval.append( "    " + XMLHandler.addTagValue( "table", tableName ) );
    retval.append( "    " + XMLHandler.addTagValue( "commit", commitSize ) );
    retval.append( "    " + XMLHandler.addTagValue( "truncate", truncateTable ) );
    retval.append( "    " + XMLHandler.addTagValue( "ignore_errors", ignoreErrors ) );
    retval.append( "    " + XMLHandler.addTagValue( "use_batch", useBatchUpdate ) );
    retval.append( "    " + XMLHandler.addTagValue( "specify_fields", specifyFields ) );

    retval.append( "    " + XMLHandler.addTagValue( "partitioning_enabled", partitioningEnabled ) );
    retval.append( "    " + XMLHandler.addTagValue( "partitioning_field", partitioningField ) );
    retval.append( "    " + XMLHandler.addTagValue( "partitioning_daily", partitioningDaily ) );
    retval.append( "    " + XMLHandler.addTagValue( "partitioning_monthly", partitioningMonthly ) );

    retval.append( "    " + XMLHandler.addTagValue( "tablename_in_field", tableNameInField ) );
    retval.append( "    " + XMLHandler.addTagValue( "tablename_field", tableNameField ) );
    retval.append( "    " + XMLHandler.addTagValue( "tablename_in_table", tableNameInTable ) );

    retval.append( "    " + XMLHandler.addTagValue( "return_keys", returningGeneratedKeys ) );
    retval.append( "    " + XMLHandler.addTagValue( "return_field", generatedKeyField ) );

    retval.append( "    <fields>" ).append( Const.CR );

    for ( int i = 0; i < fieldDatabase.length; i++ ) {
      retval.append( "        <field>" ).append( Const.CR );
      retval.append( "          " ).append( XMLHandler.addTagValue( "column_name", fieldDatabase[ i ] ) );
      retval.append( "          " ).append( XMLHandler.addTagValue( "stream_name", fieldStream[ i ] ) );
      retval.append( "        </field>" ).append( Const.CR );
    }
    retval.append( "    </fields>" ).append( Const.CR );

    return retval.toString();
  }

  public void getFields( IRowMeta row, String origin, IRowMeta[] info, TransformMeta nextTransform,
                         iVariables variables, IMetaStore metaStore ) throws HopTransformException {
    // Just add the returning key field...
    if ( returningGeneratedKeys && generatedKeyField != null && generatedKeyField.length() > 0 ) {
      IValueMeta key =
        new ValueMetaInteger( variables.environmentSubstitute( generatedKeyField ) );
      key.setOrigin( origin );
      row.addValueMeta( key );
    }
  }

  public void check( List<CheckResultInterface> remarks, PipelineMeta pipelineMeta, TransformMeta transformMeta,
                     IRowMeta prev, String[] input, String[] output, IRowMeta info, iVariables variables,
                     IMetaStore metaStore ) {
    if ( databaseMeta != null ) {
      CheckResult cr =
        new CheckResult( CheckResultInterface.TYPE_RESULT_OK, BaseMessages.getString(
          PKG, "TableOutputMeta.CheckResult.ConnectionExists" ), transformMeta );
      remarks.add( cr );

      Database db = new Database( loggingObject, databaseMeta );
      db.shareVariablesWith( pipelineMeta );
      try {
        db.connect();

        cr =
          new CheckResult( CheckResultInterface.TYPE_RESULT_OK, BaseMessages.getString(
            PKG, "TableOutputMeta.CheckResult.ConnectionOk" ), transformMeta );
        remarks.add( cr );

        if ( !Utils.isEmpty( tableName ) ) {
          String realSchemaName = db.environmentSubstitute( schemaName );
          String realTableName = db.environmentSubstitute( tableName );
          String schemaTable =
            databaseMeta.getQuotedSchemaTableCombination( realSchemaName, realTableName );
          // Check if this table exists...
          if ( db.checkTableExists( realSchemaName, realTableName ) ) {
            cr =
              new CheckResult( CheckResultInterface.TYPE_RESULT_OK, BaseMessages.getString(
                PKG, "TableOutputMeta.CheckResult.TableAccessible", schemaTable ), transformMeta );
            remarks.add( cr );

            IRowMeta r = db.getTableFieldsMeta( realSchemaName, realTableName );
            if ( r != null ) {
              cr =
                new CheckResult( CheckResultInterface.TYPE_RESULT_OK, BaseMessages.getString(
                  PKG, "TableOutputMeta.CheckResult.TableOk", schemaTable ), transformMeta );
              remarks.add( cr );

              String error_message = "";
              boolean error_found = false;
              // OK, we have the table fields.
              // Now see what we can find as previous transform...
              if ( prev != null && prev.size() > 0 ) {
                cr =
                  new CheckResult( CheckResultInterface.TYPE_RESULT_OK, BaseMessages.getString(
                    PKG, "TableOutputMeta.CheckResult.FieldsReceived", "" + prev.size() ), transformMeta );
                remarks.add( cr );

                if ( !specifyFields() ) {
                  // Starting from prev...
                  for ( int i = 0; i < prev.size(); i++ ) {
                    IValueMeta pv = prev.getValueMeta( i );
                    int idx = r.indexOfValue( pv.getName() );
                    if ( idx < 0 ) {
                      error_message += "\t\t" + pv.getName() + " (" + pv.getTypeDesc() + ")" + Const.CR;
                      error_found = true;
                    }
                  }
                  if ( error_found ) {
                    error_message =
                      BaseMessages.getString(
                        PKG, "TableOutputMeta.CheckResult.FieldsNotFoundInOutput", error_message );

                    cr = new CheckResult( CheckResultInterface.TYPE_RESULT_ERROR, error_message, transformMeta );
                    remarks.add( cr );
                  } else {
                    cr =
                      new CheckResult( CheckResultInterface.TYPE_RESULT_OK, BaseMessages.getString(
                        PKG, "TableOutputMeta.CheckResult.AllFieldsFoundInOutput" ), transformMeta );
                    remarks.add( cr );
                  }
                } else {
                  // Specifying the column names explicitly
                  for ( int i = 0; i < getFieldDatabase().length; i++ ) {
                    int idx = r.indexOfValue( getFieldDatabase()[ i ] );
                    if ( idx < 0 ) {
                      error_message += "\t\t" + getFieldDatabase()[ i ] + Const.CR;
                      error_found = true;
                    }
                  }
                  if ( error_found ) {
                    error_message =
                      BaseMessages.getString(
                        PKG, "TableOutputMeta.CheckResult.FieldsSpecifiedNotInTable", error_message );

                    cr = new CheckResult( CheckResultInterface.TYPE_RESULT_ERROR, error_message, transformMeta );
                    remarks.add( cr );
                  } else {
                    cr =
                      new CheckResult( CheckResultInterface.TYPE_RESULT_OK, BaseMessages.getString(
                        PKG, "TableOutputMeta.CheckResult.AllFieldsFoundInOutput" ), transformMeta );
                    remarks.add( cr );
                  }
                }

                error_message = "";
                if ( !specifyFields() ) {
                  // Starting from table fields in r...
                  for ( int i = 0; i < getFieldDatabase().length; i++ ) {
                    IValueMeta rv = r.getValueMeta( i );
                    int idx = prev.indexOfValue( rv.getName() );
                    if ( idx < 0 ) {
                      error_message += "\t\t" + rv.getName() + " (" + rv.getTypeDesc() + ")" + Const.CR;
                      error_found = true;
                    }
                  }
                  if ( error_found ) {
                    error_message =
                      BaseMessages.getString( PKG, "TableOutputMeta.CheckResult.FieldsNotFound", error_message );

                    cr = new CheckResult( CheckResultInterface.TYPE_RESULT_WARNING, error_message, transformMeta );
                    remarks.add( cr );
                  } else {
                    cr =
                      new CheckResult( CheckResultInterface.TYPE_RESULT_OK, BaseMessages.getString(
                        PKG, "TableOutputMeta.CheckResult.AllFieldsFound" ), transformMeta );
                    remarks.add( cr );
                  }
                } else {
                  // Specifying the column names explicitly
                  for ( int i = 0; i < getFieldStream().length; i++ ) {
                    int idx = prev.indexOfValue( getFieldStream()[ i ] );
                    if ( idx < 0 ) {
                      error_message += "\t\t" + getFieldStream()[ i ] + Const.CR;
                      error_found = true;
                    }
                  }
                  if ( error_found ) {
                    error_message =
                      BaseMessages.getString(
                        PKG, "TableOutputMeta.CheckResult.FieldsSpecifiedNotFound", error_message );

                    cr = new CheckResult( CheckResultInterface.TYPE_RESULT_ERROR, error_message, transformMeta );
                    remarks.add( cr );
                  } else {
                    cr =
                      new CheckResult( CheckResultInterface.TYPE_RESULT_OK, BaseMessages.getString(
                        PKG, "TableOutputMeta.CheckResult.AllFieldsFound" ), transformMeta );
                    remarks.add( cr );
                  }
                }
              } else {
                cr =
                  new CheckResult( CheckResultInterface.TYPE_RESULT_ERROR, BaseMessages.getString(
                    PKG, "TableOutputMeta.CheckResult.NoFields" ), transformMeta );
                remarks.add( cr );
              }
            } else {
              cr =
                new CheckResult( CheckResultInterface.TYPE_RESULT_ERROR, BaseMessages.getString(
                  PKG, "TableOutputMeta.CheckResult.TableNotAccessible" ), transformMeta );
              remarks.add( cr );
            }
          } else {
            cr =
              new CheckResult( CheckResultInterface.TYPE_RESULT_ERROR, BaseMessages.getString(
                PKG, "TableOutputMeta.CheckResult.TableError", schemaTable ), transformMeta );
            remarks.add( cr );
          }
        } else {
          cr =
            new CheckResult( CheckResultInterface.TYPE_RESULT_ERROR, BaseMessages.getString(
              PKG, "TableOutputMeta.CheckResult.NoTableName" ), transformMeta );
          remarks.add( cr );
        }
      } catch ( HopException e ) {
        cr =
          new CheckResult( CheckResultInterface.TYPE_RESULT_ERROR, BaseMessages.getString(
            PKG, "TableOutputMeta.CheckResult.UndefinedError", e.getMessage() ), transformMeta );
        remarks.add( cr );
      } finally {
        db.disconnect();
      }
    } else {
      CheckResult cr =
        new CheckResult( CheckResultInterface.TYPE_RESULT_ERROR, BaseMessages.getString(
          PKG, "TableOutputMeta.CheckResult.NoConnection" ), transformMeta );
      remarks.add( cr );
    }

    // See if we have input streams leading to this transform!
    if ( input.length > 0 ) {
      CheckResult cr =
        new CheckResult( CheckResultInterface.TYPE_RESULT_OK, BaseMessages.getString(
          PKG, "TableOutputMeta.CheckResult.ExpectedInputOk" ), transformMeta );
      remarks.add( cr );
    } else {
      CheckResult cr =
        new CheckResult( CheckResultInterface.TYPE_RESULT_ERROR, BaseMessages.getString(
          PKG, "TableOutputMeta.CheckResult.ExpectedInputError" ), transformMeta );
      remarks.add( cr );
    }
  }

  public ITransform getTransform( TransformMeta transformMeta, ITransformData data, int cnr,
                                PipelineMeta pipelineMeta, Pipeline pipeline ) {
    return new TableOutput( transformMeta, this, data, cnr, pipelineMeta, pipeline );
  }

  public ITransformData getTransformData() {
    return new TableOutputData();
  }

  public void analyseImpact( List<DatabaseImpact> impact, PipelineMeta pipelineMeta, TransformMeta transformMeta,
                             IRowMeta prev, String[] input, String[] output, IRowMeta info,
                             IMetaStore metaStore ) {
    if ( truncateTable ) {
      DatabaseImpact ii =
        new DatabaseImpact(
          DatabaseImpact.TYPE_IMPACT_TRUNCATE, pipelineMeta.getName(), transformMeta.getName(), databaseMeta
          .getDatabaseName(), tableName, "", "", "", "", "Truncate of table" );
      impact.add( ii );

    }
    // The values that are entering this transform are in "prev":
    if ( prev != null ) {
      for ( int i = 0; i < prev.size(); i++ ) {
        IValueMeta v = prev.getValueMeta( i );
        DatabaseImpact ii =
          new DatabaseImpact(
            DatabaseImpact.TYPE_IMPACT_WRITE, pipelineMeta.getName(), transformMeta.getName(), databaseMeta
            .getDatabaseName(), tableName, v.getName(), v.getName(), v != null ? v.getOrigin() : "?", "",
            "Type = " + v.toStringMeta() );
        impact.add( ii );
      }
    }
  }

  public SQLStatement getSQLStatements( PipelineMeta pipelineMeta, TransformMeta transformMeta, IRowMeta prev,
                                        IMetaStore metaStore ) {
    return getSQLStatements( pipelineMeta, transformMeta, prev, null, false, null );
  }

  public SQLStatement getSQLStatements( PipelineMeta pipelineMeta, TransformMeta transformMeta, IRowMeta prev, String tk,
                                        boolean use_autoinc, String pk ) {
    SQLStatement retval = new SQLStatement( transformMeta.getName(), databaseMeta, null ); // default: nothing to do!

    if ( databaseMeta != null ) {
      if ( prev != null && prev.size() > 0 ) {
        if ( !Utils.isEmpty( tableName ) ) {
          Database db = new Database( loggingObject, databaseMeta );
          db.shareVariablesWith( pipelineMeta );
          try {
            db.connect();

            String schemaTable = databaseMeta.getQuotedSchemaTableCombination( schemaName, tableName );
            String cr_table = db.getDDL( schemaTable, prev, tk, use_autoinc, pk );

            // Empty string means: nothing to do: set it to null...
            if ( cr_table == null || cr_table.length() == 0 ) {
              cr_table = null;
            }

            retval.setSQL( cr_table );
          } catch ( HopDatabaseException dbe ) {
            retval.setError( BaseMessages.getString( PKG, "TableOutputMeta.Error.ErrorConnecting", dbe
              .getMessage() ) );
          } finally {
            db.disconnect();
          }
        } else {
          retval.setError( BaseMessages.getString( PKG, "TableOutputMeta.Error.NoTable" ) );
        }
      } else {
        retval.setError( BaseMessages.getString( PKG, "TableOutputMeta.Error.NoInput" ) );
      }
    } else {
      retval.setError( BaseMessages.getString( PKG, "TableOutputMeta.Error.NoConnection" ) );
    }

    return retval;
  }

  public IRowMeta getRequiredFields( iVariables variables ) throws HopException {
    String realTableName = variables.environmentSubstitute( tableName );
    String realSchemaName = variables.environmentSubstitute( schemaName );

    if ( databaseMeta != null ) {
      Database db = new Database( loggingObject, databaseMeta );
      try {
        db.connect();

        if ( !Utils.isEmpty( realTableName ) ) {
          // Check if this table exists...
          if ( db.checkTableExists( realSchemaName, realTableName ) ) {
            return db.getTableFieldsMeta( realSchemaName, realTableName );
          } else {
            throw new HopException( BaseMessages.getString( PKG, "TableOutputMeta.Exception.TableNotFound" ) );
          }
        } else {
          throw new HopException( BaseMessages.getString( PKG, "TableOutputMeta.Exception.TableNotSpecified" ) );
        }
      } catch ( Exception e ) {
        throw new HopException(
          BaseMessages.getString( PKG, "TableOutputMeta.Exception.ErrorGettingFields" ), e );
      } finally {
        db.disconnect();
      }
    } else {
      throw new HopException( BaseMessages.getString( PKG, "TableOutputMeta.Exception.ConnectionNotDefined" ) );
    }

  }

  public DatabaseMeta[] getUsedDatabaseConnections() {
    if ( databaseMeta != null ) {
      return new DatabaseMeta[] { databaseMeta };
    } else {
      return super.getUsedDatabaseConnections();
    }
  }

  /**
   * @return Fields containing the values in the input stream to insert.
   */
  public String[] getFieldStream() {
    return fieldStream;
  }

  /**
   * @param fieldStream The fields containing the values in the input stream to insert in the table.
   */
  public void setFieldStream( String[] fieldStream ) {
    this.fieldStream = fieldStream;
  }

  @Override public RowMeta getRowMeta( ITransformData transformData ) {
    return (RowMeta) ( (TableOutputData) transformData ).insertRowMeta;
  }

  @Override public List<String> getDatabaseFields() {
    if ( specifyFields() ) {
      return Arrays.asList( getFieldDatabase() );
    }
    return Collections.emptyList();
  }

  @Override public List<String> getStreamFields() {
    if ( specifyFields() ) {
      return Arrays.asList( getFieldStream() );
    }
    return Collections.emptyList();

  }

  /**
   * @return Fields containing the fieldnames in the database insert.
   */
  public String[] getFieldDatabase() {
    return fieldDatabase;
  }

  /**
   * @param fieldDatabase The fields containing the names of the fields to insert.
   */
  public void setFieldDatabase( String[] fieldDatabase ) {
    this.fieldDatabase = fieldDatabase;
  }

  /**
   * @return the schemaName
   */
  public String getSchemaName() {
    return schemaName;
  }

  /**
   * @param schemaName the schemaName to set
   */
  public void setSchemaName( String schemaName ) {
    this.schemaName = schemaName;
  }

  public boolean supportsErrorHandling() {
    if ( databaseMeta != null ) {
      return databaseMeta.getIDatabase().supportsErrorHandling();
    } else {
      return true;
    }
  }

  @Override
  public String getMissingDatabaseConnectionInformationMessage() {
    // Use default connection missing message
    return null;
  }

  @Override
  public TableOutputMetaInjection getTransformMetaInjectionInterface() {
    return new TableOutputMetaInjection( this );
  }

  public List<TransformInjectionMetaEntry> extractTransformMetadataEntries() throws HopException {
    return getTransformMetaInjectionInterface().extractTransformMetadataEntries();
  }

}
